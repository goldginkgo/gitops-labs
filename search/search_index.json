{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview We use Argo CD as the GitOps engine to manage infrastructure components (Argo CD, Ingress Controller, Jenkins, SonarQube, ...) as well as business applications in our Kubernetes environments. The goal of the project is to manage all K8S resources in ArgoCD so that users don't have to do it manually through CLI. Features Infrastructure as Code Observability Auditability & Compliance Self-Healing Easy to Rollback Blue-Green/Canary/Progressive Update Strategy LDAP Integration Technologies GitOps Solution GitOps Kubernetes Nginx Ingress Controller Helm kustomize Argo CD ApplicationSet Controller Argo CD Notifications Argo CD Image Updater Argo Rollouts sealed-secrets cert-manager GitOps Managed Resources Jenkins SonarQube Nexus Velero Kaniko Trivy Elastic Cloud on Kubernetes kube-prometheus-stack","title":"Overview"},{"location":"#overview","text":"We use Argo CD as the GitOps engine to manage infrastructure components (Argo CD, Ingress Controller, Jenkins, SonarQube, ...) as well as business applications in our Kubernetes environments. The goal of the project is to manage all K8S resources in ArgoCD so that users don't have to do it manually through CLI.","title":"Overview"},{"location":"#features","text":"Infrastructure as Code Observability Auditability & Compliance Self-Healing Easy to Rollback Blue-Green/Canary/Progressive Update Strategy LDAP Integration","title":"Features"},{"location":"#technologies","text":"","title":"Technologies"},{"location":"#gitops-solution","text":"GitOps Kubernetes Nginx Ingress Controller Helm kustomize Argo CD ApplicationSet Controller Argo CD Notifications Argo CD Image Updater Argo Rollouts sealed-secrets cert-manager","title":"GitOps Solution"},{"location":"#gitops-managed-resources","text":"Jenkins SonarQube Nexus Velero Kaniko Trivy Elastic Cloud on Kubernetes kube-prometheus-stack","title":"GitOps Managed Resources"},{"location":"k8s-clusters-and-services/","text":"K8S Clusters and Services We have two kinds of Kubernetes clusters: the admin cluster and workload clusters. The admin cluster is where ArgoCD and other DevOps tools resides, and the workload cluster is the culster where business applications are deployed. Admin Cluster ArgoCD ApplicationSet Controller Argo CD Notifications Argo CD Image Updater Nginx Ingress Controller sealed-secrets cert-manager Jenkins Sonarqube Nexus Trivy Prometheus/Grafana ... Workload Clusters (DEV, TEST, QA, PROD) sealed-secrets Secrects for docker registry, certificates Nginx Ingress Controller Filebit Business applications Argo Rollouts Dynatrace Agent Velero","title":"K8S Clusters and Services"},{"location":"k8s-clusters-and-services/#k8s-clusters-and-services","text":"We have two kinds of Kubernetes clusters: the admin cluster and workload clusters. The admin cluster is where ArgoCD and other DevOps tools resides, and the workload cluster is the culster where business applications are deployed.","title":"K8S Clusters and Services"},{"location":"k8s-clusters-and-services/#admin-cluster","text":"ArgoCD ApplicationSet Controller Argo CD Notifications Argo CD Image Updater Nginx Ingress Controller sealed-secrets cert-manager Jenkins Sonarqube Nexus Trivy Prometheus/Grafana ...","title":"Admin Cluster"},{"location":"k8s-clusters-and-services/#workload-clusters-dev-test-qa-prod","text":"sealed-secrets Secrects for docker registry, certificates Nginx Ingress Controller Filebit Business applications Argo Rollouts Dynatrace Agent Velero","title":"Workload Clusters (DEV, TEST, QA, PROD)"},{"location":"roadmap/","text":"Roadmap ArgoCD Upgrade to 2.1.0 Blue Green/Canary deployment Update Image back to GitHub according to https://blog.argoproj.io/closing-ci-cd-loop-using-argoproj-a78a50a98fe8 HA deployment of Argo CD, Configuration tuning for large environments Monitoring/Logging Optimization Jenkins Jenkins shared library Validate Kubernetes manifests with kube-score , conftest or polaris . SSH using or SSH Pipeline Steps or Publish Over SSH Multi-branch pipeline Backup Cache base images for kaniko","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/#argocd","text":"Upgrade to 2.1.0 Blue Green/Canary deployment Update Image back to GitHub according to https://blog.argoproj.io/closing-ci-cd-loop-using-argoproj-a78a50a98fe8 HA deployment of Argo CD, Configuration tuning for large environments Monitoring/Logging Optimization","title":"ArgoCD"},{"location":"roadmap/#jenkins","text":"Jenkins shared library Validate Kubernetes manifests with kube-score , conftest or polaris . SSH using or SSH Pipeline Steps or Publish Over SSH Multi-branch pipeline Backup Cache base images for kaniko","title":"Jenkins"},{"location":"understaning-gitops/","text":"Understanding GitOps GitOps is a new method of Continuous Deployment that uses Git as a single source of truth for declarative infrastructure and applications, providing both revision and change control. With GitOps, a system is operated by the submission of pull requests (and subsequent merges) to the desired state of the system represented in a Git repository. Benifits Infrastructure as Code (Reproducible deployment) Code Reviews (Four-eyes principle) Declarative (Create a VM vs I have a VM) Observability Auditability & Compliance (Who changed what, when) Disaster Recovery One Click Rollback Reduce Inconsistency between Environments Better Knowledge Transfer","title":"Understanding GitOps"},{"location":"understaning-gitops/#understanding-gitops","text":"GitOps is a new method of Continuous Deployment that uses Git as a single source of truth for declarative infrastructure and applications, providing both revision and change control. With GitOps, a system is operated by the submission of pull requests (and subsequent merges) to the desired state of the system represented in a Git repository.","title":"Understanding GitOps"},{"location":"understaning-gitops/#benifits","text":"Infrastructure as Code (Reproducible deployment) Code Reviews (Four-eyes principle) Declarative (Create a VM vs I have a VM) Observability Auditability & Compliance (Who changed what, when) Disaster Recovery One Click Rollback Reduce Inconsistency between Environments Better Knowledge Transfer","title":"Benifits"},{"location":"deploy/backup-restore/","text":"Backup and Restore What to do do if ArgoCD is crashed? What to do if admin cluster is donw?","title":"Backup and Restore"},{"location":"deploy/backup-restore/#backup-and-restore","text":"","title":"Backup and Restore"},{"location":"deploy/backup-restore/#what-to-do-do-if-argocd-is-crashed","text":"","title":"What to do do if ArgoCD is crashed?"},{"location":"deploy/backup-restore/#what-to-do-if-admin-cluster-is-donw","text":"","title":"What to do if admin cluster is donw?"},{"location":"deploy/monitoring/","text":"Monitoring","title":"Monitoring"},{"location":"deploy/monitoring/#monitoring","text":"","title":"Monitoring"},{"location":"deploy/prerequisites/","text":"Prerequisites Local Desktop Install Git/kubectl/Kustomize/ArgoCD CLI locally. Provision a Kubernetes cluster The cluster should be able to create following resources. LoadBalancer service (used by ingress controller) PV (used by trivy, Jenkins, SonarQube, ...) DNS 10.224.14.210 is the example IP address for the internal Load Balancer for the admin cluster ingress controller. Add the mapping to hosts file if necessary. DNS IP Address argocd.gitops.local 10.224.14.210 jenkins.gitops.local 10.224.14.210 sonarqube.gitops.local 10.224.14.210 nexus.gitops.local 10.224.14.210 Microsoft Teams Microsoft Teams channel for notification. Refer to Microsoft Teams channel . SMTP SMTP Server: smtp.gitops.local. Whitelist the network access from kubernetes node to the SMTP server.","title":"Prerequisites"},{"location":"deploy/prerequisites/#prerequisites","text":"","title":"Prerequisites"},{"location":"deploy/prerequisites/#local-desktop","text":"Install Git/kubectl/Kustomize/ArgoCD CLI locally.","title":"Local Desktop"},{"location":"deploy/prerequisites/#provision-a-kubernetes-cluster","text":"The cluster should be able to create following resources. LoadBalancer service (used by ingress controller) PV (used by trivy, Jenkins, SonarQube, ...)","title":"Provision a Kubernetes cluster"},{"location":"deploy/prerequisites/#dns","text":"10.224.14.210 is the example IP address for the internal Load Balancer for the admin cluster ingress controller. Add the mapping to hosts file if necessary. DNS IP Address argocd.gitops.local 10.224.14.210 jenkins.gitops.local 10.224.14.210 sonarqube.gitops.local 10.224.14.210 nexus.gitops.local 10.224.14.210","title":"DNS"},{"location":"deploy/prerequisites/#microsoft-teams","text":"Microsoft Teams channel for notification. Refer to Microsoft Teams channel .","title":"Microsoft Teams"},{"location":"deploy/prerequisites/#smtp","text":"SMTP Server: smtp.gitops.local. Whitelist the network access from kubernetes node to the SMTP server.","title":"SMTP"},{"location":"deploy/security/","text":"Security Unified Secret Management with sealed-secrets We use sealed-secrets to store all the credentials and they will be synchronized to Kubernetes automatically. ArgoCD and Jenkins will pick up these secrets and use them internally. Automated Certificate Creation and Renewal We use cert-manger to generate self-signed certificates to our tools such as ArgoCD, Jenkins, etc. The certificate will also be renewed automatically when it expires. Build Container Images with Kaniko We use kaniko to build container images from Dockerfile, inside a container. Using the old Docker-in-Docker build method has following drawbacks: Docker-in-Docker requires privileged mode to function, which is a significant security concern. Docker-in-Docker generally incurs a performance penalty and can be quite slow. Docker will be deprecated in Kubernetes in the future. Container Vulnerability Scanning with Trivy We can use Trivy (also default scanner in Harbor) to scan vulnerabilities in our container images in Jenkins pipeline. Together with the warnings-ng plugin in Jenkins, a vulnerbility dashboard can be displayed.","title":"Security"},{"location":"deploy/security/#security","text":"","title":"Security"},{"location":"deploy/security/#unified-secret-management-with-sealed-secrets","text":"We use sealed-secrets to store all the credentials and they will be synchronized to Kubernetes automatically. ArgoCD and Jenkins will pick up these secrets and use them internally.","title":"Unified Secret Management with sealed-secrets"},{"location":"deploy/security/#automated-certificate-creation-and-renewal","text":"We use cert-manger to generate self-signed certificates to our tools such as ArgoCD, Jenkins, etc. The certificate will also be renewed automatically when it expires.","title":"Automated Certificate Creation and Renewal"},{"location":"deploy/security/#build-container-images-with-kaniko","text":"We use kaniko to build container images from Dockerfile, inside a container. Using the old Docker-in-Docker build method has following drawbacks: Docker-in-Docker requires privileged mode to function, which is a significant security concern. Docker-in-Docker generally incurs a performance penalty and can be quite slow. Docker will be deprecated in Kubernetes in the future.","title":"Build Container Images with Kaniko"},{"location":"deploy/security/#container-vulnerability-scanning-with-trivy","text":"We can use Trivy (also default scanner in Harbor) to scan vulnerabilities in our container images in Jenkins pipeline. Together with the warnings-ng plugin in Jenkins, a vulnerbility dashboard can be displayed.","title":"Container Vulnerability Scanning with Trivy"},{"location":"deploy/setup-ci/","text":"Setup CI Tools Nexus Configuration Sync Nexus in ArgoCD. Get default password using following command. Log in and change the password. Also enable anonymous access. # kubectl exec -it deploy/nexus-nexus-repository-manager -- cat /nexus-data/admin.password Update credentials for Nexus in sealed secrets SonarQube Configuration Sync SonarQube in ArgoCD. Log in. default user admin/admin. Change the password after login. Generate a SonarQube token in user profile and update the secret. Configure a webhook for Jenkins in SonarQube server in Administration > Configuration > Webhooks. Name: Jenkins URL: http://jenkins.gitops-system.svc.cluster.local:8080/sonarqube-webhook/ Secret: Add plugins in marketplace: PMD Jenkins Configuration Sync Jenkins in ArgoCD. We use Jenkin Configuration as Code plugin for configuring Jenkins so that no manual efforts required. When synchronizing Jenkins from ArgoCD, Jenkins will be configured. Please contact the administrator if you want to add a plugin or change system settings. Setup Jenkins Jobs When Jenkins is setup, a job called load_all_jobs is created. This job will populate all jobs defined in gitops-gitops/jenkins-jobs . Just build this job so that all other jobs will be generated. It's maybe necessary to approve the scripts in Manage Jenkins -> Script Approval. Repository Webhook Configure webhooks for push events in the repositories so that code changes can trigger Jenkins jobs automatically.","title":"Setup CI Tools"},{"location":"deploy/setup-ci/#setup-ci-tools","text":"","title":"Setup CI Tools"},{"location":"deploy/setup-ci/#nexus-configuration","text":"Sync Nexus in ArgoCD. Get default password using following command. Log in and change the password. Also enable anonymous access. # kubectl exec -it deploy/nexus-nexus-repository-manager -- cat /nexus-data/admin.password Update credentials for Nexus in sealed secrets","title":"Nexus Configuration"},{"location":"deploy/setup-ci/#sonarqube-configuration","text":"Sync SonarQube in ArgoCD. Log in. default user admin/admin. Change the password after login. Generate a SonarQube token in user profile and update the secret. Configure a webhook for Jenkins in SonarQube server in Administration > Configuration > Webhooks. Name: Jenkins URL: http://jenkins.gitops-system.svc.cluster.local:8080/sonarqube-webhook/ Secret: Add plugins in marketplace: PMD","title":"SonarQube Configuration"},{"location":"deploy/setup-ci/#jenkins-configuration","text":"Sync Jenkins in ArgoCD. We use Jenkin Configuration as Code plugin for configuring Jenkins so that no manual efforts required. When synchronizing Jenkins from ArgoCD, Jenkins will be configured. Please contact the administrator if you want to add a plugin or change system settings.","title":"Jenkins Configuration"},{"location":"deploy/setup-ci/#setup-jenkins-jobs","text":"When Jenkins is setup, a job called load_all_jobs is created. This job will populate all jobs defined in gitops-gitops/jenkins-jobs . Just build this job so that all other jobs will be generated. It's maybe necessary to approve the scripts in Manage Jenkins -> Script Approval.","title":"Setup Jenkins Jobs"},{"location":"deploy/setup-ci/#repository-webhook","text":"Configure webhooks for push events in the repositories so that code changes can trigger Jenkins jobs automatically.","title":"Repository Webhook"},{"location":"deploy/setup/","text":"Setup GitOps Core Components Install sealed-secrets Install sealed-secrets in the Kubernetes cluster. git clone https://github.com/goldginkgo/gitops-labs.git cd gitops-labs k apply -f namespaces helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets helm dependency build sealed-secrets helm install sealed-secrets sealed-secrets Intall kubeseal client in you local Ubuntu desktop. wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.16.0/kubeseal-linux-amd64 -O kubeseal sudo install -m 755 kubeseal /usr/local/bin/kubeseal kubeseal --fetch-cert --controller-name=sealed-secrets --controller-namespace=gitops-system > seal-pub-cert.pem # cert expires in 30 days Example of how to use sealed-secrets kubectl create secret generic my-secret --from-literal=key1=supersecret --from-literal=key2=topsecret --dry-run=client -o yaml | kubeseal --cert seal-pub-cert.pem -o yaml Create secrets in the Cluster k apply -f secrets Deploy ArgoCD and other tools kustomize build argocd | kubectl apply -f - k apply -f app-of-apps.yaml","title":"Setup GitOps Core Components"},{"location":"deploy/setup/#setup-gitops-core-components","text":"","title":"Setup GitOps Core Components"},{"location":"deploy/setup/#install-sealed-secrets","text":"Install sealed-secrets in the Kubernetes cluster. git clone https://github.com/goldginkgo/gitops-labs.git cd gitops-labs k apply -f namespaces helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets helm dependency build sealed-secrets helm install sealed-secrets sealed-secrets Intall kubeseal client in you local Ubuntu desktop. wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.16.0/kubeseal-linux-amd64 -O kubeseal sudo install -m 755 kubeseal /usr/local/bin/kubeseal kubeseal --fetch-cert --controller-name=sealed-secrets --controller-namespace=gitops-system > seal-pub-cert.pem # cert expires in 30 days Example of how to use sealed-secrets kubectl create secret generic my-secret --from-literal=key1=supersecret --from-literal=key2=topsecret --dry-run=client -o yaml | kubeseal --cert seal-pub-cert.pem -o yaml","title":"Install sealed-secrets"},{"location":"deploy/setup/#create-secrets-in-the-cluster","text":"k apply -f secrets","title":"Create secrets in the Cluster"},{"location":"deploy/setup/#deploy-argocd-and-other-tools","text":"kustomize build argocd | kubectl apply -f - k apply -f app-of-apps.yaml","title":"Deploy ArgoCD and other tools"},{"location":"deploy/upgrade/","text":"Upgrade Upgrade ArgoCD Currently we use v2.0.4 of ArgoCD. If you want to upgrade ArgoCD, please replace the gitops-labs/argocd/base/install.yaml file with the latest one. Upgrade Jenkins Update the Dokcerfile in jenkins-docker repository. The Jenkins job gitops/jenkins-docker will be executed automatically. Image tag will bump up a minor version, as well as the new git tag in the repository. Update the image tag in gitops-labs/jenkins/values.yaml . [Optional] Update the Helm chart version in gitops-labs/jenkins/Chart.yaml . Restart the jenkins statefulset in ArgoCD UI.","title":"Upgrade"},{"location":"deploy/upgrade/#upgrade","text":"","title":"Upgrade"},{"location":"deploy/upgrade/#upgrade-argocd","text":"Currently we use v2.0.4 of ArgoCD. If you want to upgrade ArgoCD, please replace the gitops-labs/argocd/base/install.yaml file with the latest one.","title":"Upgrade ArgoCD"},{"location":"deploy/upgrade/#upgrade-jenkins","text":"Update the Dokcerfile in jenkins-docker repository. The Jenkins job gitops/jenkins-docker will be executed automatically. Image tag will bump up a minor version, as well as the new git tag in the repository. Update the image tag in gitops-labs/jenkins/values.yaml . [Optional] Update the Helm chart version in gitops-labs/jenkins/Chart.yaml . Restart the jenkins statefulset in ArgoCD UI.","title":"Upgrade Jenkins"},{"location":"faq/known-issues/","text":"Known Issues rpc error: code = Unknown desc = Get \"...\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) Namespace gitops-system get stuck in terminating state when deleting ArgoCD. https://vuptime.io/cards/k8s_remove_a_namespace_stuck_in_terminating/ kubectl delete apps <app_name> -n <namespace> did not work for me. The response application.argoproj.io \"<app_name>\" deleted looks like it worked, but if I kubectl get apps -n <namespace>, the app still remains. I had a finalizer in the app, going in and editing that to - finalizer: [] allowed it to delete. cert-manager is installed in cert-manager namespace rather than gitops-system namespace because of technical issues. ArgoCD CLI may have issues as there is no ingress resource for gRPC. After configuring Pod Templates in Jenkins, the Command to run section will be changed to sleep , remove the value and keep it empty for jnlp agents. sealed-secrets will not update existings secrets","title":"Known Issues"},{"location":"faq/known-issues/#known-issues","text":"rpc error: code = Unknown desc = Get \"...\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) Namespace gitops-system get stuck in terminating state when deleting ArgoCD. https://vuptime.io/cards/k8s_remove_a_namespace_stuck_in_terminating/ kubectl delete apps <app_name> -n <namespace> did not work for me. The response application.argoproj.io \"<app_name>\" deleted looks like it worked, but if I kubectl get apps -n <namespace>, the app still remains. I had a finalizer in the app, going in and editing that to - finalizer: [] allowed it to delete. cert-manager is installed in cert-manager namespace rather than gitops-system namespace because of technical issues. ArgoCD CLI may have issues as there is no ingress resource for gRPC. After configuring Pod Templates in Jenkins, the Command to run section will be changed to sleep , remove the value and keep it empty for jnlp agents. sealed-secrets will not update existings secrets","title":"Known Issues"},{"location":"user-guide/basic-usage/","text":"Basic Usage Add a new K8S environment Install sealed-secrets on the cluster. Get kubernetes credentials. Create credentail <env>-cluster-credentials in sealed-secrets. Add file gitops-labs/argocd/base/project-<env>.yaml . Add file gitops-labs/argocd/base/cluster-<env>-secret-sync.yaml . Add the files in gitops-labs/argocd/kustomization.yaml . Add file gitops-labs/secrets/<env>/<namespace>-regsecret-sync.yaml for docker registry credentials. You need to delete existing secret because sealed-secrets can not update existing secrets. Add file gitops-labs/applications/<env>/<env>-secrets.yaml , gitops-labs/applications/<env>/<env>-mlp-apps.yaml . Add the above file in gitops-labs/applications/kustomization.yaml . Add dynatrace support in the cluster. Currently it's done manually. Add Velero manually. Manage a new application Example application. apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: <name> namespace: gitops-system annotations: argocd.argoproj.io/manifest-generate-paths: /<manifest-path> # notifications.argoproj.io/subscribe.on-created.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-deleted.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-deployed.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-health-degraded.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-failed.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-status-unknown.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-succeeded.teams: argocd-notifications # Add a this finalizer ONLY if you want these to cascade delete. # finalizers: # - resources-finalizer.argocd.argoproj.io spec: project: <project-name> source: repoURL: https://github.com/goldginkgo/gitops-labs/<repository> targetRevision: HEAD path: <manifest-path> destination: server: <cluster-url> namespace: <namespace> syncPolicy: automated: # automated sync by default retries failed attempts 5 times with following delays between attempts ( 5s, 10s, 20s, 40s, 80s ); retry controlled using `retry` field. prune: true # Specifies if resources should be pruned during auto-syncing ( false by default ). selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ). # allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ). syncOptions: # Sync options which modifies sync behavior - Validate=false # disables resource validation (equivalent to 'kubectl apply --validate=false') ( true by default ). - CreateNamespace=true # Namespace Auto-Creation ensures that namespace specified as the application destination exists in the destination cluster. - ApplyOutOfSyncOnly=true - PrunePropagationPolicy=foreground # Supported policies are background, foreground and orphan. - PruneLast=true # Allow the ability for resource pruning to happen as a final, implicit wave of a sync operation retry: limit: 5 # number of failed sync attempt retries; unlimited number of attempts if less than 0 backoff: duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. \"2m\", \"1h\") factor: 2 # a factor to multiply the base duration after each failed retry maxDuration: 3m # the maximum amount of time allowed for the backoff strategy # # Ignore differences at the specified json pointers # ignoreDifferences: # - group: apps # kind: Deployment # jsonPointers: # - /spec/replicas Rollback applications to previous state It is as simple as do a Git revert in GitHub. How to troubleshoot issues Disable automated syncing for app-of-apps application. Diable automated syncing for the application in trouble. Troubleshoot manually for the application. Enable automated syncing again. Self Healing If manual changes are done in the target K8S cluster, ArgoCD will reconcile the changes and retore to the desired state when automated syncing is enabled for the application.","title":"Basic Usage"},{"location":"user-guide/basic-usage/#basic-usage","text":"","title":"Basic Usage"},{"location":"user-guide/basic-usage/#add-a-new-k8s-environment","text":"Install sealed-secrets on the cluster. Get kubernetes credentials. Create credentail <env>-cluster-credentials in sealed-secrets. Add file gitops-labs/argocd/base/project-<env>.yaml . Add file gitops-labs/argocd/base/cluster-<env>-secret-sync.yaml . Add the files in gitops-labs/argocd/kustomization.yaml . Add file gitops-labs/secrets/<env>/<namespace>-regsecret-sync.yaml for docker registry credentials. You need to delete existing secret because sealed-secrets can not update existing secrets. Add file gitops-labs/applications/<env>/<env>-secrets.yaml , gitops-labs/applications/<env>/<env>-mlp-apps.yaml . Add the above file in gitops-labs/applications/kustomization.yaml . Add dynatrace support in the cluster. Currently it's done manually. Add Velero manually.","title":"Add a new K8S environment"},{"location":"user-guide/basic-usage/#manage-a-new-application","text":"Example application. apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: <name> namespace: gitops-system annotations: argocd.argoproj.io/manifest-generate-paths: /<manifest-path> # notifications.argoproj.io/subscribe.on-created.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-deleted.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-deployed.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-health-degraded.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-failed.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-status-unknown.teams: argocd-notifications # notifications.argoproj.io/subscribe.on-sync-succeeded.teams: argocd-notifications # Add a this finalizer ONLY if you want these to cascade delete. # finalizers: # - resources-finalizer.argocd.argoproj.io spec: project: <project-name> source: repoURL: https://github.com/goldginkgo/gitops-labs/<repository> targetRevision: HEAD path: <manifest-path> destination: server: <cluster-url> namespace: <namespace> syncPolicy: automated: # automated sync by default retries failed attempts 5 times with following delays between attempts ( 5s, 10s, 20s, 40s, 80s ); retry controlled using `retry` field. prune: true # Specifies if resources should be pruned during auto-syncing ( false by default ). selfHeal: true # Specifies if partial app sync should be executed when resources are changed only in target Kubernetes cluster and no git change detected ( false by default ). # allowEmpty: false # Allows deleting all application resources during automatic syncing ( false by default ). syncOptions: # Sync options which modifies sync behavior - Validate=false # disables resource validation (equivalent to 'kubectl apply --validate=false') ( true by default ). - CreateNamespace=true # Namespace Auto-Creation ensures that namespace specified as the application destination exists in the destination cluster. - ApplyOutOfSyncOnly=true - PrunePropagationPolicy=foreground # Supported policies are background, foreground and orphan. - PruneLast=true # Allow the ability for resource pruning to happen as a final, implicit wave of a sync operation retry: limit: 5 # number of failed sync attempt retries; unlimited number of attempts if less than 0 backoff: duration: 5s # the amount to back off. Default unit is seconds, but could also be a duration (e.g. \"2m\", \"1h\") factor: 2 # a factor to multiply the base duration after each failed retry maxDuration: 3m # the maximum amount of time allowed for the backoff strategy # # Ignore differences at the specified json pointers # ignoreDifferences: # - group: apps # kind: Deployment # jsonPointers: # - /spec/replicas","title":"Manage a new application"},{"location":"user-guide/basic-usage/#rollback-applications-to-previous-state","text":"It is as simple as do a Git revert in GitHub.","title":"Rollback applications to previous state"},{"location":"user-guide/basic-usage/#how-to-troubleshoot-issues","text":"Disable automated syncing for app-of-apps application. Diable automated syncing for the application in trouble. Troubleshoot manually for the application. Enable automated syncing again.","title":"How to troubleshoot issues"},{"location":"user-guide/basic-usage/#self-healing","text":"If manual changes are done in the target K8S cluster, ArgoCD will reconcile the changes and retore to the desired state when automated syncing is enabled for the application.","title":"Self Healing"},{"location":"user-guide/continuous-integration/","text":"Continuous Integration Jenkins Jobs Use Job DSL to define Jenkins jobs in a programmatic way. Refer to DSL API reference . Jobs are defined in gitops-gitops/jenkins-jobs . Example pipelineJob('gitops/docker-jenkins') { definition { cpsScm { scm { git { remote { url('https://github.com/goldginkgo/jenkins-docker.git') } branch('*/master') } } lightweight() } } triggers { githubPush() } } Jenkinsfile Agents Currently we recommend to use the maven38 agent. It has severl containers: kaniko, maven, trivy. Build Images We should use kaniko to build container images from Dockerfile, inside a container. Security Scanning An example pipeline. pipeline { agent { label \"maven38\" } options { // timestamps() // \u65e5\u5fd7\u4f1a\u6709\u65f6\u95f4 skipDefaultCheckout() // \u5220\u9664\u9690\u5f0fcheckout scm\u8bed\u53e5 disableConcurrentBuilds() //\u7981\u6b62\u5e76\u884c timeout(time:10, unit:'MINUTES') //\u8bbe\u7f6e\u6d41\u6c34\u7ebf\u8d85\u65f6\u65f6\u95f4 } // environment { // ACR_REGISTRY_CREDS = credentials('acepi001cr01_username_pass') // } stages { stage('VulnerabilityScan') { steps { container(\"trivy\"){ script{ sh ''' # export TRIVY_USERNAME=${ACR_REGISTRY_CREDS_USR} # export TRIVY_PASSWORD=${ACR_REGISTRY_CREDS_PSW} trivy client --remote http://trivy.gitops-system:4954 -f json -o trivy-report.json goldginkgo/jenkins:0.1 ''' } } } } } post { always { recordIssues(tools: [trivy(pattern: 'trivy-report.json')]) } } } Remote Command Execution to VMs Under development. Full Jenkinsfile Example @Library(\"jenkins-library\") def tools = new org.devops.v1.tools() def sendEmail = new org.devops.v1.sendEmail() pipeline { agent { label \"maven38\"} options { //timestamps() // \u65e5\u5fd7\u4f1a\u6709\u65f6\u95f4 skipDefaultCheckout() // \u5220\u9664\u9690\u5f0fcheckout scm\u8bed\u53e5 disableConcurrentBuilds() //\u7981\u6b62\u5e76\u884c timeout(time:10, unit:'MINUTES') //\u8bbe\u7f6e\u6d41\u6c34\u7ebf\u8d85\u65f6\u65f6\u95f4 } environment { GIT_URL = \"goldgingo/jenkins-demo.git\" GIT_BRANCH = \"master\" BUILD_SHELL = \"mvn clean package -Dmaven.tet.skip=true\" IMAGE = \"goldginkgo/jenkins-demo\" IMAGE_TAG = \"0.1\" TO_EMAIL_USER = \"frank.dai@test.cn\" GITHUB_CREDS = credentials('github_username_pass') ACR_REGISTRY_CREDS = credentials('acepi001cr01_username_pass') } stages { stage('GetCode') { steps { checkout([$class: 'GitSCM', branches: [[name: \"${GIT_BRANCH}\"]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: 'github_username_pass', url: \"http://${GIT_URL}\"]]]) } } stage('Build&Test') { steps { container('maven') { script{ tools.PrintMes(\"\u7f16\u8bd1\u6253\u5305\", \"blue\") sh \"\"\" ${BUILD_SHELL} \"\"\" } } } } stage('CodeScanner') { steps{ container('maven') { withSonarQubeEnv(installationName: 'SonarQube') { script{ tools.PrintMes(\"\u9759\u6001\u626b\u63cf\", \"blue\") sh 'mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.7.0.1746:sonar' } } } } } stage(\"QualityGate\") { steps { script{ tools.PrintMes(\"\u8d28\u91cf\u95e8\", \"blue\") } timeout(time: 1, unit: 'HOURS') { waitForQualityGate abortPipeline: true } } } stage('BuildImage') { steps { container(\"kaniko\") { script{ tools.PrintMes(\"\u521b\u5efa\u955c\u50cf\", \"blue\") sh \"/kaniko/executor -f `pwd`/Dockerfile -c `pwd` --destination=${IMAGE}:${IMAGE_TAG} --cache=true --cache-dir=/kanikocache --skip-tls-verify\" } } } } stage('VulnerabilityScan') { steps { container(\"trivy\"){ script{ tools.PrintMes(\"\u6f0f\u6d1e\u626b\u63cf\", \"blue\") sh ''' export TRIVY_USERNAME=${ACR_REGISTRY_CREDS_USR} export TRIVY_PASSWORD=${ACR_REGISTRY_CREDS_PSW} trivy client --remote http://trivy.gitops-system:4954 -f json -o trivy-report.json ${IMAGE}:${IMAGE_TAG} ''' } } } } stage('Deploy') { when { branch 'master' } input { message 'Should we continue?' ok 'Yes, we should.' parameters { string(name: 'input', defaultValue: 'yes', description: 'continue deployment?') } } steps { script{ tools.PrintMes(\"\u662f\u5426\u90e8\u7f72\uff1f\", \"blue\") isDeploy = \"${input}\" if (\"${isDeploy}\" == 'yes' && \"${GIT_BRANCH}\" == 'master') { tools.PrintMes(\"\u5f00\u59cb\u90e8\u7f72\", \"blue\") sh \"\"\" git remote set-url origin http://${GITHUB_CREDS_USR}:${GITHUB_CREDS_PSW}@${GIT_URL} git checkout ${GIT_BRANCH} git config --global user.email \"jenkins2@gitops.cn\" git config --global user.name \"Jenkins Bot\" git pull origin master # sed -i 's/{IMAGE}:[0-9]*\\\\.[0-9]*/{IMAGE}:${IMAGE_TAG}/g' application-demo.yaml # git status # git commit -am 'Bump up image version' # git tag -a ${IMAGE_TAG} -m \"version ${IMAGE_TAG}\" # git push origin master --tags \"\"\" } else { tools.PrintMes(\"\u4e0d\u90e8\u7f72\", \"blue\") } } } } } post { success { script{ tools.PrintMes(\"Success:\u6784\u5efa\u6210\u529f\", \"green\") currentBuild.description += \"\\n\u6784\u5efa\u6210\u529f!\" sendEmail.SendEmail(\"\u6784\u5efa\u6210\u529f\", TO_EMAIL_USER) } } failure { script{ tools.PrintMes(\"Failure:\u6784\u5efa\u5931\u8d25\", \"red\") currentBuild.description += \"\\n\u6784\u5efa\u5931\u8d25!\" sendEmail.SendEmail(\"\u6784\u5efa\u5931\u8d25\", TO_EMAIL_USER) } } aborted { script{ tools.PrintMes(\"Aborted:\u6784\u5efa\u53d6\u6d88\", \"red\") currentBuild.description += \"\\n\u6784\u5efa\u53d6\u6d88!\" sendEmail.SendEmail(\"\u6784\u5efa\u53d6\u6d88\", TO_EMAIL_USER) } } always { recordIssues(tools: [trivy(pattern: 'trivy-report.json')]) } } }","title":"Continuous Integration"},{"location":"user-guide/continuous-integration/#continuous-integration","text":"","title":"Continuous Integration"},{"location":"user-guide/continuous-integration/#jenkins-jobs","text":"Use Job DSL to define Jenkins jobs in a programmatic way. Refer to DSL API reference . Jobs are defined in gitops-gitops/jenkins-jobs .","title":"Jenkins Jobs"},{"location":"user-guide/continuous-integration/#example","text":"pipelineJob('gitops/docker-jenkins') { definition { cpsScm { scm { git { remote { url('https://github.com/goldginkgo/jenkins-docker.git') } branch('*/master') } } lightweight() } } triggers { githubPush() } }","title":"Example"},{"location":"user-guide/continuous-integration/#jenkinsfile","text":"","title":"Jenkinsfile"},{"location":"user-guide/continuous-integration/#agents","text":"Currently we recommend to use the maven38 agent. It has severl containers: kaniko, maven, trivy.","title":"Agents"},{"location":"user-guide/continuous-integration/#build-images","text":"We should use kaniko to build container images from Dockerfile, inside a container.","title":"Build Images"},{"location":"user-guide/continuous-integration/#security-scanning","text":"An example pipeline. pipeline { agent { label \"maven38\" } options { // timestamps() // \u65e5\u5fd7\u4f1a\u6709\u65f6\u95f4 skipDefaultCheckout() // \u5220\u9664\u9690\u5f0fcheckout scm\u8bed\u53e5 disableConcurrentBuilds() //\u7981\u6b62\u5e76\u884c timeout(time:10, unit:'MINUTES') //\u8bbe\u7f6e\u6d41\u6c34\u7ebf\u8d85\u65f6\u65f6\u95f4 } // environment { // ACR_REGISTRY_CREDS = credentials('acepi001cr01_username_pass') // } stages { stage('VulnerabilityScan') { steps { container(\"trivy\"){ script{ sh ''' # export TRIVY_USERNAME=${ACR_REGISTRY_CREDS_USR} # export TRIVY_PASSWORD=${ACR_REGISTRY_CREDS_PSW} trivy client --remote http://trivy.gitops-system:4954 -f json -o trivy-report.json goldginkgo/jenkins:0.1 ''' } } } } } post { always { recordIssues(tools: [trivy(pattern: 'trivy-report.json')]) } } }","title":"Security Scanning"},{"location":"user-guide/continuous-integration/#remote-command-execution-to-vms","text":"Under development.","title":"Remote Command Execution to VMs"},{"location":"user-guide/continuous-integration/#full-jenkinsfile-example","text":"@Library(\"jenkins-library\") def tools = new org.devops.v1.tools() def sendEmail = new org.devops.v1.sendEmail() pipeline { agent { label \"maven38\"} options { //timestamps() // \u65e5\u5fd7\u4f1a\u6709\u65f6\u95f4 skipDefaultCheckout() // \u5220\u9664\u9690\u5f0fcheckout scm\u8bed\u53e5 disableConcurrentBuilds() //\u7981\u6b62\u5e76\u884c timeout(time:10, unit:'MINUTES') //\u8bbe\u7f6e\u6d41\u6c34\u7ebf\u8d85\u65f6\u65f6\u95f4 } environment { GIT_URL = \"goldgingo/jenkins-demo.git\" GIT_BRANCH = \"master\" BUILD_SHELL = \"mvn clean package -Dmaven.tet.skip=true\" IMAGE = \"goldginkgo/jenkins-demo\" IMAGE_TAG = \"0.1\" TO_EMAIL_USER = \"frank.dai@test.cn\" GITHUB_CREDS = credentials('github_username_pass') ACR_REGISTRY_CREDS = credentials('acepi001cr01_username_pass') } stages { stage('GetCode') { steps { checkout([$class: 'GitSCM', branches: [[name: \"${GIT_BRANCH}\"]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: 'github_username_pass', url: \"http://${GIT_URL}\"]]]) } } stage('Build&Test') { steps { container('maven') { script{ tools.PrintMes(\"\u7f16\u8bd1\u6253\u5305\", \"blue\") sh \"\"\" ${BUILD_SHELL} \"\"\" } } } } stage('CodeScanner') { steps{ container('maven') { withSonarQubeEnv(installationName: 'SonarQube') { script{ tools.PrintMes(\"\u9759\u6001\u626b\u63cf\", \"blue\") sh 'mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.7.0.1746:sonar' } } } } } stage(\"QualityGate\") { steps { script{ tools.PrintMes(\"\u8d28\u91cf\u95e8\", \"blue\") } timeout(time: 1, unit: 'HOURS') { waitForQualityGate abortPipeline: true } } } stage('BuildImage') { steps { container(\"kaniko\") { script{ tools.PrintMes(\"\u521b\u5efa\u955c\u50cf\", \"blue\") sh \"/kaniko/executor -f `pwd`/Dockerfile -c `pwd` --destination=${IMAGE}:${IMAGE_TAG} --cache=true --cache-dir=/kanikocache --skip-tls-verify\" } } } } stage('VulnerabilityScan') { steps { container(\"trivy\"){ script{ tools.PrintMes(\"\u6f0f\u6d1e\u626b\u63cf\", \"blue\") sh ''' export TRIVY_USERNAME=${ACR_REGISTRY_CREDS_USR} export TRIVY_PASSWORD=${ACR_REGISTRY_CREDS_PSW} trivy client --remote http://trivy.gitops-system:4954 -f json -o trivy-report.json ${IMAGE}:${IMAGE_TAG} ''' } } } } stage('Deploy') { when { branch 'master' } input { message 'Should we continue?' ok 'Yes, we should.' parameters { string(name: 'input', defaultValue: 'yes', description: 'continue deployment?') } } steps { script{ tools.PrintMes(\"\u662f\u5426\u90e8\u7f72\uff1f\", \"blue\") isDeploy = \"${input}\" if (\"${isDeploy}\" == 'yes' && \"${GIT_BRANCH}\" == 'master') { tools.PrintMes(\"\u5f00\u59cb\u90e8\u7f72\", \"blue\") sh \"\"\" git remote set-url origin http://${GITHUB_CREDS_USR}:${GITHUB_CREDS_PSW}@${GIT_URL} git checkout ${GIT_BRANCH} git config --global user.email \"jenkins2@gitops.cn\" git config --global user.name \"Jenkins Bot\" git pull origin master # sed -i 's/{IMAGE}:[0-9]*\\\\.[0-9]*/{IMAGE}:${IMAGE_TAG}/g' application-demo.yaml # git status # git commit -am 'Bump up image version' # git tag -a ${IMAGE_TAG} -m \"version ${IMAGE_TAG}\" # git push origin master --tags \"\"\" } else { tools.PrintMes(\"\u4e0d\u90e8\u7f72\", \"blue\") } } } } } post { success { script{ tools.PrintMes(\"Success:\u6784\u5efa\u6210\u529f\", \"green\") currentBuild.description += \"\\n\u6784\u5efa\u6210\u529f!\" sendEmail.SendEmail(\"\u6784\u5efa\u6210\u529f\", TO_EMAIL_USER) } } failure { script{ tools.PrintMes(\"Failure:\u6784\u5efa\u5931\u8d25\", \"red\") currentBuild.description += \"\\n\u6784\u5efa\u5931\u8d25!\" sendEmail.SendEmail(\"\u6784\u5efa\u5931\u8d25\", TO_EMAIL_USER) } } aborted { script{ tools.PrintMes(\"Aborted:\u6784\u5efa\u53d6\u6d88\", \"red\") currentBuild.description += \"\\n\u6784\u5efa\u53d6\u6d88!\" sendEmail.SendEmail(\"\u6784\u5efa\u53d6\u6d88\", TO_EMAIL_USER) } } always { recordIssues(tools: [trivy(pattern: 'trivy-report.json')]) } } }","title":"Full Jenkinsfile Example"},{"location":"user-guide/deployment-strategy/","text":"Deployment Strategy Progressive Delivery Blue-Green Deployment Canary Deployment","title":"Deployment Strategy"},{"location":"user-guide/deployment-strategy/#deployment-strategy","text":"","title":"Deployment Strategy"},{"location":"user-guide/deployment-strategy/#progressive-delivery","text":"","title":"Progressive Delivery"},{"location":"user-guide/deployment-strategy/#blue-green-deployment","text":"","title":"Blue-Green Deployment"},{"location":"user-guide/deployment-strategy/#canary-deployment","text":"","title":"Canary Deployment"},{"location":"user-guide/libraries/","text":"Libraries Jenkins Shared Library Refer to jenkins-library .","title":"Libraries"},{"location":"user-guide/libraries/#libraries","text":"","title":"Libraries"},{"location":"user-guide/libraries/#jenkins-shared-library","text":"Refer to jenkins-library .","title":"Jenkins Shared Library"}]}